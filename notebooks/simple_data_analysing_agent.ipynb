{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9IjmEbbJ63p44Zizvug3t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dllochini/ai-dataset-agent/blob/main/notebooks/simple_data_analysing_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yM89NylAbzJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas matplotlib seaborn openai gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EgkWHzr3IUju",
        "outputId": "88c4da1d-91e6-4a4b-ece0-73a41b6ca46b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.17.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 229, in _get_updated_criteria\n",
            "    for requirement in self._p.get_dependencies(candidate=candidate):\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 247, in get_dependencies\n",
            "    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 402, in iter_dependencies\n",
            "    yield from self._factory.make_requirements_from_spec(str(r), self._ireq)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 581, in make_requirements_from_spec\n",
            "    ireq = self._make_install_req_from_spec(specifier, comes_from)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/req/constructors.py\", line 431, in install_req_from_req_string\n",
            "    req = get_requirement(req_string)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/packaging.py\", line 45, in get_requirement\n",
            "    return Requirement(req_string)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/requirements.py\", line 36, in __init__\n",
            "    parsed = _parse_requirement(requirement_string)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/_parser.py\", line 62, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/_tokenizer.py\", line 105, in __init__\n",
            "    name: re.compile(pattern) for name, pattern in rules.items()\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/re/__init__.py\", line 226, in compile\n",
            "    def compile(pattern, flags=0):\n",
            "    \n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/style.py\", line 146, in __init__\n",
            "    def _make_color(color: Union[Color, str]) -> Color:\n",
            "                           ~~~~~^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 395, in inner\n",
            "    return _caches[func](*args, **kwds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 517, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 736, in Union\n",
            "    return _UnionGenericAlias(self, parameters)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 1275, in __init__\n",
            "    self.__parameters__ = _collect_parameters(args)\n",
            "    ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 1215, in __setattr__\n",
            "    def __setattr__(self, attr, val):\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "euKBB2zcG0pj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import re\n",
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "from google.colab import files, userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get(\"GROQ_API_KEY\"),\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "print(\"Upload your dataset (CSV):\")\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "display(df.head())\n",
        "'''"
      ],
      "metadata": {
        "id": "v_MVtQDeIgR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a dataset analysis AI agent.\n",
        "\n",
        "You operate strictly in the following loop:\n",
        "\n",
        "Thought -> Action -> PAUSE -> Observation -> Thought -> ... -> Answer\n",
        "\n",
        "GENERAL RULES :\n",
        "\n",
        "1. You must either:\n",
        "   - Call exactly ONE Action and then output PAUSE\n",
        "   OR\n",
        "   - Output a final Answer.\n",
        "\n",
        "2. After calling an Action, you MUST format it exactly as:\n",
        "\n",
        "Action: <action_name>[: <column_name_if_required>]\n",
        "PAUSE\n",
        "\n",
        "3. After PAUSE, you will receive:\n",
        "Observation: <tool_output>\n",
        "\n",
        "4. After receiving an Observation:\n",
        "   - You MUST continue reasoning.\n",
        "   - If the observation already contains all information required to answer the user's question,\n",
        "     you MUST immediately output:\n",
        "\n",
        "Answer: <final result>\n",
        "\n",
        "   - Do NOT call additional actions if the answer can already be produced.\n",
        "   - Do NOT recompute values that are already present in the Observation.\n",
        "   - Do NOT repeat the same action unless absolutely necessary.\n",
        "\n",
        "5. Never output an empty message.\n",
        "6. Never output PAUSE unless you are calling an Action.\n",
        "7. Never output Observation yourself.\n",
        "8. Use exact column names when required.\n",
        "9. Only perform actions directly necessary to answer the question.\n",
        "10. If a single action provides enough information, immediately produce Answer.\n",
        "\n",
        "SPECIAL RULES :\n",
        "\n",
        "• If the user asks for an overview:\n",
        "  - Only call dataset_overview.\n",
        "  - After receiving the observation, immediately produce Answer.\n",
        "\n",
        "• If the user asks for a statistical summary:\n",
        "  - Only call statistical_summary.\n",
        "  - After receiving the observation, immediately produce Answer.\n",
        "  - Do NOT call column_mean or other actions afterward.\n",
        "\n",
        "AVAILABLE ACTIONS:\n",
        "\n",
        "dataset_overview\n",
        "statistical_summary\n",
        "missing_values\n",
        "duplicate_count\n",
        "column_mean: <column_name>\n",
        "column_min: <column_name>\n",
        "column_max: <column_name>\n",
        "value_counts: <column_name>\n",
        "correlation_matrix\n",
        "number_of_rows\n",
        "number_of_columns\n",
        "plot_numeric_columns\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZUtmrtTJNj7R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_overview(df, column=None):\n",
        "    return {\n",
        "        \"rows\": df.shape[0],\n",
        "        \"columns\": df.shape[1],\n",
        "        \"column_names\": df.columns.tolist(),\n",
        "        \"dtypes\": df.dtypes.astype(str).to_dict()\n",
        "    }\n",
        "\n",
        "def statistical_summary(df, column=None):\n",
        "    return df.describe(include='number').to_dict()\n",
        "\n",
        "def missing_values(df, column=None):\n",
        "    return df.isnull().sum().to_dict()\n",
        "\n",
        "def duplicate_count(df, column=None):\n",
        "    return int(df.duplicated().sum())\n",
        "\n",
        "def column_mean(df, column=None):\n",
        "    if column is None or column not in df.columns:\n",
        "        return \"Column not found.\"\n",
        "    return df[column].mean()\n",
        "\n",
        "def column_min(df, column=None):\n",
        "    if column is None or column not in df.columns:\n",
        "        return \"Column not found.\"\n",
        "    return df[column].min()\n",
        "\n",
        "def column_max(df, column=None):\n",
        "    if column is None or column not in df.columns:\n",
        "        return \"Column not found.\"\n",
        "    return df[column].max()\n",
        "\n",
        "def value_counts(df, column=None):\n",
        "    if column is None or column not in df.columns:\n",
        "        return \"Column not found.\"\n",
        "    return df[column].value_counts().to_dict()\n",
        "\n",
        "def correlation_matrix(df, column=None):\n",
        "    return df.corr(numeric_only=True)\n",
        "\n",
        "def number_of_rows(df, column=None):\n",
        "    return df.shape[0]\n",
        "\n",
        "def number_of_columns(df, column=None):\n",
        "    return df.shape[1]\n",
        "\n",
        "def plot_numeric_columns(df, column=None, save_dir=\"plots\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    saved_paths = []\n",
        "    for col in numeric_cols:\n",
        "        plt.figure()\n",
        "        sns.histplot(df[col], kde=True)\n",
        "        plt.title(f\"Distribution of {col}\")\n",
        "        path = os.path.join(save_dir, f\"{col}.png\")\n",
        "        plt.savefig(path)\n",
        "        plt.close()\n",
        "        saved_paths.append(path)\n",
        "    return saved_paths\n",
        "\n",
        "KNOWN_ACTIONS = {\n",
        "    \"dataset_overview\": dataset_overview,\n",
        "    \"statistical_summary\": statistical_summary,\n",
        "    \"missing_values\": missing_values,\n",
        "    \"duplicate_count\": duplicate_count,\n",
        "    \"column_mean\": column_mean,\n",
        "    \"column_min\": column_min,\n",
        "    \"column_max\": column_max,\n",
        "    \"value_counts\": value_counts,\n",
        "    \"correlation_matrix\": correlation_matrix,\n",
        "    \"number_of_rows\": number_of_rows,\n",
        "    \"number_of_columns\": number_of_columns,\n",
        "    \"plot_numeric_columns\": plot_numeric_columns,\n",
        "}"
      ],
      "metadata": {
        "id": "FHP-tVW5NqD6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, system_prompt):\n",
        "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "    def __call__(self, message):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",\n",
        "            messages=self.messages,\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
        "\n",
        "        return content\n"
      ],
      "metadata": {
        "id": "y4aaXBAyIQBl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot = Agent(system_prompt=SYSTEM_PROMPT)"
      ],
      "metadata": {
        "id": "ti3TumUqn8Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 1"
      ],
      "metadata": {
        "id": "Wzr3C5tanYvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "que = \"give me a overview of the datatset\"\n",
        "\n",
        "print(bot(que))"
      ],
      "metadata": {
        "id": "pDGJl7WKn_02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = dataset_overview(current_df)\n",
        "print('function result :', result)\n",
        "next_prompt = \"Observation: {}\".format(result)\n",
        "print(next_prompt)"
      ],
      "metadata": {
        "id": "sXOGJxLRnYGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot(next_prompt)"
      ],
      "metadata": {
        "id": "H4Wa15S2n069"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 2"
      ],
      "metadata": {
        "id": "K8GV7rU1pXXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "que = \"What is the minimum math_score?\"\n",
        "\n",
        "print(bot(que))"
      ],
      "metadata": {
        "id": "_Swzul7uotft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = column_min(df,\"math_score\")\n",
        "print(result)\n",
        "next_prompt = \"Observation: {}\".format(result)\n",
        "print(next_prompt)"
      ],
      "metadata": {
        "id": "iYpKBWVUoJvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot(next_prompt)"
      ],
      "metadata": {
        "id": "leq5Yh9uo5Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 3"
      ],
      "metadata": {
        "id": "0vQFEZ-dpZk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "que = \"give me a statistical overview of the datatset\"\n",
        "\n",
        "print(bot(que))"
      ],
      "metadata": {
        "id": "EOgwov2Io-dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = statistical_summary(df)\n",
        "print(result)\n",
        "next_prompt = \"Observation: {}\".format(result)\n",
        "print(next_prompt)"
      ],
      "metadata": {
        "id": "p941p_ropEOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot(next_prompt)"
      ],
      "metadata": {
        "id": "tMi6cfi2pJgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Loop"
      ],
      "metadata": {
        "id": "tBTfUfyvqqOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_re = re.compile(r\"Action:\\s*(\\w+)(?::\\s*(.*))?\")\n",
        "\n",
        "def query_loop(question, df, max_iters=8):\n",
        "    agent = Agent(SYSTEM_PROMPT)\n",
        "    reasoning_steps = []\n",
        "    next_input = question\n",
        "    images = None\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        output = agent(next_input)\n",
        "        reasoning_steps.append(output)\n",
        "\n",
        "        if not output.strip():\n",
        "            return \"Model returned empty response.\", reasoning_steps, images\n",
        "\n",
        "        if \"Answer:\" in output:\n",
        "            final_answer = output.split(\"Answer:\", 1)[1].strip()\n",
        "            return final_answer, reasoning_steps, images\n",
        "\n",
        "        match = action_re.search(output)\n",
        "\n",
        "        if match:\n",
        "\n",
        "            if \"PAUSE\" not in output:\n",
        "                return \"Protocol error: Model must output PAUSE after Action.\", reasoning_steps, images\n",
        "\n",
        "            action_name = match.group(1).strip().lower()\n",
        "            action_input = match.group(2).strip() if match.group(2) else None\n",
        "\n",
        "            if action_name not in KNOWN_ACTIONS:\n",
        "                message = f\"Unable to perform action '{action_name}' — this action is not supported.\"\n",
        "                reasoning_steps.append(message)\n",
        "                next_input = f\"Observation: {message}\"\n",
        "                continue\n",
        "\n",
        "            observation = KNOWN_ACTIONS[action_name](df, action_input)\n",
        "\n",
        "            if action_name == \"plot_numeric_columns\":\n",
        "                images = observation\n",
        "\n",
        "            try:\n",
        "                serialized = json.dumps(observation, default=str)\n",
        "            except:\n",
        "                serialized = str(observation)\n",
        "\n",
        "            reasoning_steps.append(f\"Observation (JSON): {serialized}\")\n",
        "            next_input = f\"Observation: {serialized}\"\n",
        "            continue\n",
        "\n",
        "    return (\n",
        "        \"The agent stopped after too many reasoning steps. \"\n",
        "        \"This query may not be supported yet. Please try one of the available actions above.\",\n",
        "        reasoning_steps,\n",
        "        images\n",
        "    )"
      ],
      "metadata": {
        "id": "l0l0DqyHqoLF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "que = [\"Give me an overview of this dataset.\",\n",
        "       \"How many rows and columns are there?\",\n",
        "       \"List all column names and their data types.\",\n",
        "       \"Tell me which columns are numeric and which are categorical.\",\n",
        "       \"Provide a statistical summary for all numeric columns.\",\n",
        "       \"Give me the mean, min, max, and standard deviation of all columns.\",\n",
        "       \"Show descriptive statistics of this dataset.\",\n",
        "       \"What is the mean age of students?\",\n",
        "       \"What is the maximum math_score?\",\n",
        "       \"How many unique values are in the gender column?\",\n",
        "       \"Check which columns have missing values.\",\n",
        "       \"Are there any duplicate rows?\",\n",
        "       \"Give me the correlation matrix for numeric columns.\",\n",
        "       \"Plot the distribution of all numeric columns.\",\n",
        "       \"Which student has the highest science_score and what is their attendance_percentage?\",\n",
        "       \"Compare math_score and english_score correlation and mean values.\",\n",
        "       \"Give me the mean of all columns.\",\n",
        "       \"How many students have attendance_percentage above 90?\"\n",
        "       ]\n",
        "\n",
        "query_loop(que[5], df)"
      ],
      "metadata": {
        "id": "m5rMBbDkrTDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = \"\"\"\n",
        "Welcome! This AI Dataset Analysis Agent helps you explore and analyze your datasets interactively.\n",
        "\n",
        "You can ask it to:\n",
        "\n",
        "- **Get an overview of the dataset**: rows, columns, column names, and data types.\n",
        "- **Generate a statistical summary** of numeric columns, including mean, standard deviation, min, max, and percentiles.\n",
        "- **Check for missing values** in any column.\n",
        "- **Count duplicate rows** in the dataset.\n",
        "- **Get column-specific insights** such as mean, min, max, or value counts.\n",
        "- **Compute the correlation matrix** between numeric columns.\n",
        "- **Get the total number of rows or columns**.\n",
        "- **Visualize numeric columns** with histograms (plots will appear in the gallery).\n",
        "\n",
        "The agent uses step-by-step reasoning to answer your questions. Type your query about the dataset, and it will show its reasoning along with a final answer.\n",
        "\n",
        "*Note:* Only supported actions from the above list can be performed. Queries outside these actions may not be answered.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZDC7ii84ytwS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_df = None\n",
        "\n",
        "def load_file(file):\n",
        "    global current_df\n",
        "    if file is None:\n",
        "        return \"No file uploaded.\", None\n",
        "    current_df = pd.read_csv(file)\n",
        "    return f\"Dataset '{file}' loaded successfully with {current_df.shape[0]} rows and {current_df.shape[1]} columns.\", None\n",
        "\n",
        "def chat_interface(file, user_input):\n",
        "    global current_df\n",
        "\n",
        "    if current_df is None:\n",
        "        if file is None:\n",
        "            return \"Please upload a dataset first.\", None\n",
        "        current_df = pd.read_csv(file)\n",
        "\n",
        "    if not user_input:\n",
        "        return \"Please enter a question about the dataset.\", None\n",
        "\n",
        "    answer, reasoning, images = query_loop(user_input, current_df)\n",
        "    return answer, images\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=chat_interface,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload your CSV dataset\", type=\"filepath\"),\n",
        "        gr.Textbox(label=\"Ask a question about your dataset\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"Agent Response\"),\n",
        "        gr.Gallery(label=\"Generated Plots\")\n",
        "    ],\n",
        "    title=\"AI Dataset Analysis Agent\",\n",
        "    description=description\n",
        ")\n",
        "\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "22uWgxBFylXg",
        "outputId": "543273fe-6d49-4503-c398-1d1c8d6229b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3720b4015b9a25d7b1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3720b4015b9a25d7b1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}